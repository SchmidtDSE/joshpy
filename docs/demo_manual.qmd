---
title: "joshpy Parameter Sweep Demo (Manual Workflow)"
format: html
execute:
  warning: false
---

```{r}
#| label: setup
#| include: false
library(reticulate)
library(ggplot2)
library(dplyr)
```

## Introduction

[Josh](https://joshsim.org) is an ecological simulation runtime for agent-based
modeling developed by the [Eric and Wendy Schmidt Center for Data Science and Environment](https://github.com/SchmidtDSE/josh).
This demo assumes familiarity with Josh's simulation language and runtime.

**joshpy** is a Python client that enables:

- **Orchestration**: Define parameter sweeps, expand job configurations, and
  execute simulations programmatically
- **Tracking**: Register runs in a DuckDB-backed registry with session and
  config tracking
- **Data Loading**: Import cell-level CSV exports into queryable tables
- **Analysis**: Query results across parameter values and replicates
- **Diagnostics**: Quick matplotlib visualizations for simulation sanity checks
- **Visualization**: Create publication-quality plots with R/ggplot2 integration

This demo walks through a complete parameter sweep workflow **using each component
directly**. This approach provides maximum control and visibility into each step.
For a simplified workflow using `SweepManager`, see `demo_sweep_manager.qmd`.

We vary the `maxGrowth` parameter from 10 to 100 meters/step across 10 experiments,
each with 3 replicates, then load, query, and visualize the results.

## Prerequisites

Ensure the Josh JAR is available at `jar/joshsim-fat.jar` and joshpy is installed:

```bash
pip install -e '.[all]'
```

For visualization, ensure R is installed with the following packages:

```r
install.packages(c("reticulate", "ggplot2", "dplyr"))
```

## Step 1: Setup - Define Parameter Sweep

The first step is to define our experiment configuration. joshpy uses three key
abstractions:

- **`JobConfig`**: The top-level configuration specifying source files, templates,
  and sweep parameters
- **`SweepConfig`**: Defines which parameters to sweep and their values
- **`SweepParameter`**: A single parameter with a name and list of values

The `JobExpander` will later compute the cartesian product of all parameters,
generating one job per combination.

```{python}
from pathlib import Path

from joshpy.jobs import JobConfig, SweepConfig, SweepParameter

# Paths to source files
SOURCE_PATH = Path("../examples/hello_cli_configurable.josh")
TEMPLATE_PATH = Path("../examples/templates/sweep_config.jshc.j2")

# Parameter sweep: maxGrowth from 10 to 100 in steps of 10
MAX_GROWTH_VALUES = list(range(10, 101, 10))

config = JobConfig(
    template_path=TEMPLATE_PATH,
    source_path=SOURCE_PATH,
    simulation="Main",
    replicates=3,
    sweep=SweepConfig(
        parameters=[SweepParameter(name="maxGrowth", values=MAX_GROWTH_VALUES)]
    ),
)

print(f"Parameter values: {MAX_GROWTH_VALUES}")
print(f"Replicates per job: {config.replicates}")
print(f"Total runs: {len(MAX_GROWTH_VALUES)} x {config.replicates} = {len(MAX_GROWTH_VALUES) * config.replicates}")
```

Let's examine the source files. The `.josh` file defines the simulation, and
the `.jshc.j2` template provides parameterized configuration:

#### Josh Source

```{python}
print(SOURCE_PATH.read_text())
```

#### Template Configuration

```{python}
print(TEMPLATE_PATH.read_text())
```

Notice that the `.josh` file references `config sweep_config.maxGrowth` - this
pulls the value from our generated config file at runtime.

## Step 2: Initialize Registry and Expand Jobs

The `RunRegistry` provides experiment tracking backed by DuckDB. It stores:

- **Sessions**: High-level experiment metadata
- **Configs**: Rendered configuration files with parameter values and input file hashes
- **Runs**: Individual execution records with timing and exit codes

The `JobExpander` takes our `JobConfig` and generates concrete jobs - one per
parameter combination, each with a unique **run hash** for tracking. The run hash
includes the `.josh` file content, rendered `.jshc` content, and hashes of any
input data files.

```{python}
from joshpy.jobs import JobExpander
from joshpy.registry import RunRegistry

# Create in-memory registry for this demo
registry = RunRegistry(":memory:")

# Expand config into individual jobs
expander = JobExpander()
job_set = expander.expand(config)

# Create a session to track this experiment
session_id = registry.create_session(
    experiment_name="growth_rate_sweep",
    simulation="Main",
    template_path=str(TEMPLATE_PATH),
    metadata={"job_config": config.to_dict()},  # Store for reconstruction
)
print(f"Session ID: {session_id}")
print(f"Will run {job_set.total_jobs} jobs ({job_set.total_replicates} replicates)")

# Register each job's configuration in the registry
for job in job_set.jobs:
    registry.register_run(
        session_id=session_id,
        run_hash=job.run_hash,
        josh_path=str(job.source_path),
        config_content=job.config_content,
        file_mappings=job.file_mappings,
        parameters=job.parameters,
    )
    print(f"  maxGrowth={job.parameters['maxGrowth']:>3} -> hash={job.run_hash}")
```

## Step 3: Run the Simulations

The `JoshCLI` executes jobs via the Josh command-line interface. The `run_sweep()`
function handles execution and automatically records runs in the registry when
`registry` and `session_id` are provided.

```{python}
from joshpy.cli import JoshCLI
from joshpy.jobs import run_sweep

# Update session status
registry.update_session_status(session_id, "running")

# Create CLI targeting the local fat JAR
cli = JoshCLI(josh_jar=Path("../jar/joshsim-fat.jar"))

print("Running 10 experiments (3 replicates each)...\n")

# Run all jobs with automatic tracking
results = run_sweep(cli, job_set, registry=registry, session_id=session_id)

print(f"\nCompleted: {results.succeeded}/{len(results)} succeeded")

# Update final session status
final_status = "completed" if results.failed == 0 else "failed"
registry.update_session_status(session_id, final_status)
```

## Step 4: Load Cell Data from CSVs

Josh exports simulation data to CSV files. The `recover_sweep_results()` function
automatically discovers export paths from the Josh file (using `inspect_exports`),
resolves template variables for each job, and loads results into the registry.

```{python}
from joshpy.sweep import recover_sweep_results

print("Loading CSV exports into registry...")

# Automatically discover and load CSV results
total_loaded = recover_sweep_results(cli, job_set, registry)

print(f"\nLoaded {total_loaded:,} rows")
```

## Step 5: Diagnostic Plotting (Python)

The `SimulationDiagnostics` class provides quick matplotlib-based visualizations
for simulation sanity checks - useful for verifying that simulations behave as
expected before deeper analysis.

### Discover Available Data

First, let's see what data is available in the registry:

```{python}
# Get summary of loaded data
summary = registry.get_data_summary()
print(summary)
```

We can also query individual lists:

```{python}
print(f"Export variables: {registry.list_export_variables()}")
print(f"Config parameters: {registry.list_config_parameters()}")
print(f"Entity types: {registry.list_entity_types()}")
```

### Time Series Visualization

The `plot_timeseries()` method shows how a variable evolves over simulation steps.
By default, it spatially aggregates across patches and shows uncertainty bands
across replicates.

```{python}
#| label: fig-diag-timeseries
#| fig-cap: "Tree height over time for maxGrowth=50, with uncertainty bands across replicates."

from joshpy.diagnostics import SimulationDiagnostics

diag = SimulationDiagnostics(registry)

# Plot time series for a specific parameter value
# Filter by maxGrowth=50 to see a single experiment
diag.plot_timeseries(
    "averageHeight",
    maxGrowth=50,
    title="Average Tree Height Over Time (maxGrowth=50)",
    show=True,
)
```

### Parameter Comparison

The `plot_comparison()` method compares a variable across different parameter
values - ideal for visualizing parameter sweep results.

```{python}
#| label: fig-diag-comparison
#| fig-cap: "Tree height trajectories across all maxGrowth parameter values."

# Compare averageHeight across all maxGrowth values
diag.plot_comparison(
    "averageHeight",
    group_by="maxGrowth",
    title="Tree Height by Growth Rate Parameter",
    show=True,
)
```

We can also create a bar chart at a specific timestep:

```{python}
#| label: fig-diag-barchart
#| fig-cap: "Final tree height at step 10 for each maxGrowth value."

# Bar chart at final step
diag.plot_comparison(
    "averageHeight",
    group_by="maxGrowth",
    step=10,
    title="Final Tree Height vs Growth Rate",
    show=True,
)
```

### Saving Figures

All plot methods return a matplotlib Figure that can be saved:

```{python}
# Save to file instead of showing inline
fig = diag.plot_comparison(
    "averageHeight",
    group_by="maxGrowth",
    show=False,
)
fig.savefig("/tmp/diagnostic_comparison.png", dpi=150, bbox_inches="tight")
print("Saved to /tmp/diagnostic_comparison.png")
```

## Step 6: Visualize Results (R)

For publication-quality figures or more customized visualizations, we can pass
data to R for visualization using ggplot2. The `DiagnosticQueries` class provides
ready-made queries that return pandas DataFrames, which we can export to CSV for R.

First, let's query the data and export it:

```{python}
from joshpy.cell_data import DiagnosticQueries

queries = DiagnosticQueries(registry)

# Compare averageHeight across all maxGrowth values
df = queries.get_parameter_comparison(
    variable="averageHeight",
    param_name="maxGrowth",
)

print(f"Retrieved {len(df)} rows\n")
if not df.empty:
    print("Sample data (first 15 rows):")
    print(df.head(15).to_string(index=False))
    # Save to CSV for R visualization
    df.to_csv("/tmp/sweep_results.csv", index=False)
    print("\nSaved results to /tmp/sweep_results.csv")
```

Now we can use ggplot2 in R to create publication-quality figures:

1. **Time series**: Tree height over simulation steps with ribbon for uncertainty
2. **Bar chart**: Final height vs growth rate parameter with error bars

```{r}
#| label: fig-timeseries
#| fig-cap: "Tree height trajectories for different maxGrowth parameter values. Higher growth rates produce taller trees, as expected."
#| fig-width: 10
#| fig-height: 6

# Read results from CSV exported by Python
df <- read.csv("/tmp/sweep_results.csv")

if (nrow(df) > 0) {
  p <- ggplot(df, aes(x = step, y = mean_value, color = factor(param_value), fill = factor(param_value))) +
    geom_ribbon(aes(ymin = mean_value - std_value, ymax = mean_value + std_value), alpha = 0.2, color = NA) +
    geom_line(linewidth = 0.8) +
    geom_point(size = 2) +
    labs(
      x = "Simulation Step",
      y = "Average Tree Height (meters)",
      title = "Tree Growth Over Time by maxGrowth Parameter",
      color = "maxGrowth",
      fill = "maxGrowth"
    ) +
    theme_minimal() +
    theme(
      legend.position = "right",
      panel.grid.minor = element_blank()
    )
  print(p)
} else {
  cat("No data to plot.")
}
```

```{r}
#| label: fig-final-height
#| fig-cap: "Final tree height vs growth rate parameter. Error bars show standard deviation across replicates."
#| fig-width: 10
#| fig-height: 6

# Read results from CSV exported by Python
df <- read.csv("/tmp/sweep_results.csv")

if (nrow(df) > 0) {
  final_df <- df |>
    dplyr::filter(step == max(step))

  p <- ggplot(final_df, aes(x = param_value, y = mean_value)) +
    geom_col(fill = "steelblue", alpha = 0.7) +
    geom_errorbar(
      aes(ymin = mean_value - std_value, ymax = mean_value + std_value),
      width = 3,
      linewidth = 0.6
    ) +
    labs(
      x = "maxGrowth (meters/step)",
      y = "Final Average Height (meters)",
      title = "Final Tree Height vs Growth Rate"
    ) +
    theme_minimal() +
    theme(panel.grid.minor = element_blank())
  print(p)

  # Calculate and print correlation
  r <- cor(final_df$param_value, final_df$mean_value)
  cat(sprintf("\nCorrelation between maxGrowth and final height: r = %.4f\n", r))
} else {
  cat("No data to plot.")
}
```

## Summary

This demo illustrated the manual joshpy workflow using each component directly:

1. **Define** a parameter sweep using `JobConfig` and `SweepConfig`
2. **Expand** jobs with `JobExpander` to get concrete job specifications
3. **Register** jobs with `registry.register_run()` for tracking
4. **Execute** with `run_sweep()` and `RegistryCallback` for automatic recording
5. **Load** outputs with `recover_sweep_results()` for automatic path discovery
6. **Query** with `DiagnosticQueries` or direct DuckDB access
7. **Visualize** with `SimulationDiagnostics` (Python) or ggplot2 (R)

**Key Design Principles:**

- **Thin CLI wrapper**: `JoshCLI` maps 1:1 to CLI commands
- **Thin DuckDB wrapper**: Direct `registry.conn` access for custom SQL
- **Convenience helpers**: `run_sweep()` and `recover_sweep_results()` for common patterns
- **Full control**: Each step is explicit and visible

For a simplified workflow, see `demo_sweep_manager.qmd` which uses `SweepManager`
to encapsulate these steps.

## Cleanup

```{python}
job_set.cleanup()  # Remove temporary config files
registry.close()
print("Cleanup complete.")
```
