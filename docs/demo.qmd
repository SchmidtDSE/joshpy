---
title: "joshpy Parameter Sweep Demo"
format: html
execute:
  warning: false
---

```{r}
#| label: setup
#| include: false
library(reticulate)
library(ggplot2)
library(dplyr)
```

## Introduction

[Josh](https://joshsim.org) is an ecological simulation runtime for agent-based
modeling developed by the [Eric and Wendy Schmidt Center for Data Science and Environment](https://github.com/SchmidtDSE/josh).
This demo assumes familiarity with Josh's simulation language and runtime.

**joshpy** is a Python client that enables:

- **Orchestration**: Define parameter sweeps, expand job configurations, and
  execute simulations programmatically
- **Tracking**: Register runs in a DuckDB-backed registry with session and
  config tracking
- **Data Loading**: Import cell-level CSV exports into queryable tables
- **Analysis**: Query results across parameter values and replicates
- **Visualization**: Create plots comparing simulation outcomes

This demo walks through a complete parameter sweep workflow. We vary the
`maxGrowth` parameter from 10 to 100 meters/step across 10 experiments, each
with 3 replicates, then load, query, and visualize the results.

## Prerequisites

Ensure the Josh JAR is available at `jar/joshsim-fat.jar` and joshpy is installed:

```bash
pip install -e '.[all]'
```

For visualization, ensure R is installed with the following packages:

```r
install.packages(c("reticulate", "ggplot2", "dplyr"))
```

## Step 1: Setup - Define Parameter Sweep

The first step is to define our experiment configuration. joshpy uses three key
abstractions:

- **`JobConfig`**: The top-level configuration specifying source files, templates,
  and sweep parameters
- **`SweepConfig`**: Defines which parameters to sweep and their values
- **`SweepParameter`**: A single parameter with a name and list of values

The `JobExpander` will later compute the cartesian product of all parameters,
generating one job per combination.

```{python}
from pathlib import Path

from joshpy.jobs import JobConfig, SweepConfig, SweepParameter

# Paths to source files
SOURCE_PATH = Path("../examples/hello_cli_configurable.josh")
TEMPLATE_PATH = Path("../examples/templates/sweep_config.jshc.j2")

# Parameter sweep: maxGrowth from 10 to 100 in steps of 10
MAX_GROWTH_VALUES = list(range(10, 101, 10))

config = JobConfig(
    template_path=TEMPLATE_PATH,
    source_path=SOURCE_PATH,
    simulation="Main",
    replicates=3,
    sweep=SweepConfig(
        parameters=[SweepParameter(name="maxGrowth", values=MAX_GROWTH_VALUES)]
    ),
)

print(f"Parameter values: {MAX_GROWTH_VALUES}")
print(f"Replicates per job: {config.replicates}")
print(f"Total runs: {len(MAX_GROWTH_VALUES)} x {config.replicates} = {len(MAX_GROWTH_VALUES) * config.replicates}")
```

Let's examine the source files. The `.josh` file defines the simulation, and
the `.jshc.j2` template provides parameterized configuration:

#### Josh Source

```{python}
print(SOURCE_PATH.read_text())
```

#### Template Configuration

```{python}
print(TEMPLATE_PATH.read_text())
```

Notice that the `.josh` file references `config sweep_config.maxGrowth` - this
pulls the value from our generated config file at runtime.

## Step 2: Initialize Registry and Expand Jobs

The `RunRegistry` provides experiment tracking backed by DuckDB. It stores:

- **Sessions**: High-level experiment metadata
- **Configs**: Rendered configuration files with parameter values
- **Runs**: Individual execution records with timing and exit codes

The `JobExpander` takes our `JobConfig` and generates concrete jobs - one per
parameter combination, each with a unique config hash for tracking.

```{python}
from joshpy.jobs import JobExpander
from joshpy.registry import RunRegistry

# Create in-memory registry for this demo
registry = RunRegistry(":memory:")

# Create a session to track this experiment
session_id = registry.create_session(
    experiment_name="growth_rate_sweep",
    simulation="Main",
    total_jobs=len(MAX_GROWTH_VALUES),
    total_replicates=len(MAX_GROWTH_VALUES) * config.replicates,
    template_path=str(TEMPLATE_PATH),
)
print(f"Session ID: {session_id}")

# Expand config into individual jobs
expander = JobExpander()
job_set = expander.expand(config)
print(f"Expanded to {len(job_set)} jobs")

# Register each job's config in the registry
for job in job_set.jobs:
    registry.register_config(
        session_id=session_id,
        config_hash=job.config_hash,
        config_content=job.config_content,
        parameters=job.parameters,
    )
    print(f"  maxGrowth={job.parameters['maxGrowth']:>3} -> hash={job.config_hash}")
```

## Step 3: Run the Simulations

The `JobRunner` executes jobs via the Josh CLI. It builds the appropriate
command-line invocation including:

- Source file and simulation name
- Config file path (via `--data` flag)
- Custom tags for template variable resolution (via `--custom-tag`)
- Replicate count

The `RegistryCallback` automatically records run metadata as each job completes.

```{python}
from joshpy.jobs import JobRunner
from joshpy.registry import RegistryCallback

# Update session status
registry.update_session_status(session_id, "running")

# Create runner targeting the local fat JAR
runner = JobRunner(josh_jar=Path("../jar/joshsim-fat.jar"))
callback = RegistryCallback(registry, session_id)

print("Running 10 experiments (3 replicates each)...")
print("=" * 60)

results = []
for job in job_set.jobs:
    result = runner.run(job)
    callback(result)
    results.append(result)
    status = "OK" if result.success else "FAIL"
    print(f"[{status}] maxGrowth={job.parameters['maxGrowth']}")
    if not result.success:
        print(f"       Error: {result.stderr[:200]}...")

print("=" * 60)
succeeded = sum(1 for r in results if r.success)
print(f"Completed: {succeeded}/{len(results)} succeeded")

# Update final session status
final_status = "completed" if succeeded == len(results) else "failed"
registry.update_session_status(session_id, final_status)
```

## Step 4: Load Cell Data from CSVs

Josh exports simulation data to CSV files. The `CellDataLoader` imports these
into a DuckDB `cell_data` table, linking each row to its originating run via
`run_id` and `config_hash`. This enables queries that join parameters with
results.

```{python}
from joshpy.cell_data import CellDataLoader

loader = CellDataLoader(registry)

print("Loading CSV exports into registry...")
total_loaded = 0
files_found = 0

for result in results:
    if not result.success:
        continue

    job = result.job
    mg = job.parameters["maxGrowth"]

    # Get run_id from registry (created by RegistryCallback)
    runs = registry.get_runs_for_config(job.config_hash)
    if not runs:
        print(f"  Skipping maxGrowth={mg} (no run_id)")
        continue

    run_id = runs[0].run_id

    # Load each replicate's CSV
    for rep in range(job.replicates):
        csv_path = Path(f"/tmp/hello_josh_{mg}_{rep}.csv")
        if csv_path.exists():
            rows = loader.load_csv(csv_path, run_id=run_id, config_hash=job.config_hash)
            total_loaded += rows
            files_found += 1

print(f"\nLoaded {total_loaded:,} rows from {files_found} files")
```

## Step 5: Query Results

The `DiagnosticQueries` class provides ready-made queries for common analysis
patterns. The `get_parameter_comparison()` method aggregates a variable across
parameter values and timesteps, computing mean and standard deviation across
replicates.

```{python}
from joshpy.cell_data import DiagnosticQueries

queries = DiagnosticQueries(registry)

# Compare averageHeight across all maxGrowth values
df = queries.get_parameter_comparison(
    variable="averageHeight",
    param_name="maxGrowth",
)

print(f"Retrieved {len(df)} rows\n")
if not df.empty:
    print("Sample data (first 15 rows):")
    print(df.head(15).to_string(index=False))
    # Save to CSV for R visualization
    df.to_csv("/tmp/sweep_results.csv", index=False)
    print("\nSaved results to /tmp/sweep_results.csv")
```

## Step 6: Visualize Results

With data in a pandas DataFrame, we can pass it to R for visualization using
ggplot2. We'll create two plots:

1. **Time series**: Tree height over simulation steps with ribbon for uncertainty
2. **Bar chart**: Final height vs growth rate parameter with error bars

```{r}
#| label: fig-timeseries
#| fig-cap: "Tree height trajectories for different maxGrowth parameter values. Higher growth rates produce taller trees, as expected."
#| fig-width: 10
#| fig-height: 6

# Read results from CSV exported by Python
df <- read.csv("/tmp/sweep_results.csv")

if (nrow(df) > 0) {
  p <- ggplot(df, aes(x = step, y = mean_value, color = factor(param_value), fill = factor(param_value))) +
    geom_ribbon(aes(ymin = mean_value - std_value, ymax = mean_value + std_value), alpha = 0.2, color = NA) +
    geom_line(linewidth = 0.8) +
    geom_point(size = 2) +
    labs(
      x = "Simulation Step",
      y = "Average Tree Height (meters)",
      title = "Tree Growth Over Time by maxGrowth Parameter",
      color = "maxGrowth",
      fill = "maxGrowth"
    ) +
    theme_minimal() +
    theme(
      legend.position = "right",
      panel.grid.minor = element_blank()
    )
  print(p)
} else {
  cat("No data to plot.")
}
```

```{r}
#| label: fig-final-height
#| fig-cap: "Final tree height vs growth rate parameter. Error bars show standard deviation across replicates."
#| fig-width: 10
#| fig-height: 6

# Read results from CSV exported by Python
df <- read.csv("/tmp/sweep_results.csv")

if (nrow(df) > 0) {
  final_df <- df |>
    dplyr::filter(step == max(step))

  p <- ggplot(final_df, aes(x = param_value, y = mean_value)) +
    geom_col(fill = "steelblue", alpha = 0.7) +
    geom_errorbar(
      aes(ymin = mean_value - std_value, ymax = mean_value + std_value),
      width = 3,
      linewidth = 0.6
    ) +
    labs(
      x = "maxGrowth (meters/step)",
      y = "Final Average Height (meters)",
      title = "Final Tree Height vs Growth Rate"
    ) +
    theme_minimal() +
    theme(panel.grid.minor = element_blank())
  print(p)

  # Calculate and print correlation
  r <- cor(final_df$param_value, final_df$mean_value)
  cat(sprintf("\nCorrelation between maxGrowth and final height: r = %.4f\n", r))
} else {
  cat("No data to plot.")
}
```

## Summary

This demo illustrated the core joshpy workflow:

1. **Define** a parameter sweep using `JobConfig` and `SweepConfig`
2. **Track** experiments with `RunRegistry` sessions and configs
3. **Execute** simulations via `JobRunner` with automatic tracking
4. **Load** CSV outputs into queryable DuckDB tables
5. **Query** results across parameters using `DiagnosticQueries`
6. **Visualize** parameter sensitivity with ggplot2 in R

The registry-backed approach ensures reproducibility and enables complex
queries joining parameters with results across multiple experiments.

This document also demonstrates Quarto's ability to seamlessly combine R and
Python in the same workflow using `reticulate`. Python handles the simulation
orchestration and data querying, while R handles visualization with ggplot2.

## Cleanup

```{python}
registry.close()
print("Registry closed.")
```
